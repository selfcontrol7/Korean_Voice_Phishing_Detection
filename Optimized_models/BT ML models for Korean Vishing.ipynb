{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c826e5f980e3fd4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data Augmentation with Back-translation method on Imbalanced Text Dataset for Korean Vishing Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4be264b14a357",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If CUDA is available, print the current GPU details\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU Index:\", torch.cuda.current_device())\n",
    "    print(\"Current GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    print(\"GPU Memory Allocated:\", torch.cuda.memory_allocated())\n",
    "    print(\"GPU Memory Cached:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff0575ebd3b320",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "# General\n",
    "from time import time\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import sys\n",
    "import subprocess\n",
    "from collections import Counter\n",
    "\n",
    "# EDA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "# NLP \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# ML\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, fbeta_score, roc_auc_score, matthews_corrcoef, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ba057e5a8fee5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data importation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd0b535a41f658",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import the train, validation and the test sets\n",
    "print('Loading datasets...')\n",
    "train_set= pd.read_csv('training_set.csv')\n",
    "val_set = pd.read_csv('validation_set.csv')\n",
    "test_set = pd.read_csv('test_set.csv')\n",
    "\n",
    "# import all augmented dataset\n",
    "train_set_ch = pd.read_csv('vishing_dataset_CH_AUG.csv')\n",
    "train_set_en = pd.read_csv('vishing_dataset_EN_AUG.csv')\n",
    "train_set_ja = pd.read_csv('vishing_dataset_JA_AUG.csv')\n",
    "\n",
    "print('Datasets loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734ccda2a78f7c75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Delete all the rows in train_set_en, train_set_ja and train_set_ch that have label 0\n",
    "train_set_ch = train_set_ch[train_set_ch['label'] != 0]\n",
    "train_set_en = train_set_en[train_set_en['label'] != 0]\n",
    "train_set_ja = train_set_ja[train_set_ja['label'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a00923031f3d98",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_class_distribution(data, title):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    # sns.set(style=\"ticks\")\n",
    "    ax = sns.countplot(x='label', data=data)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Annotate the bars with the number of samples\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='baseline', fontsize=11, color='black', xytext=(0, 5),\n",
    "                    textcoords='offset points')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa3d3e44a666f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#plot the distribution of the datasets\n",
    "plot_class_distribution(train_set, 'Train Dataset Class Distribution')\n",
    "plot_class_distribution(val_set, 'Validation Dataset Class Distribution')\n",
    "plot_class_distribution(test_set, 'Test Dataset Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e18fe364cefd77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#plot the distribution of the datasets\n",
    "plot_class_distribution(train_set_en, '(English Augmented) Train Dataset Class Distribution')\n",
    "plot_class_distribution(train_set_ja, '(Japanese Augmented) Train Dataset Class Distribution')\n",
    "plot_class_distribution(train_set_ch, '(Chinese Augmented) Train Dataset Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68849d5133724a8f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_set.info()\n",
    "val_set.info()\n",
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd1249b90f0e16",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_set_en.info()\n",
    "train_set_ja.info()\n",
    "train_set_ch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc062af783712d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# drop the colum we don't need\n",
    "train_set.drop(['id'], axis=1, inplace=True)\n",
    "val_set.drop(['id'], axis=1, inplace=True)\n",
    "test_set.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "#check the dataframes\n",
    "train_set.info()\n",
    "val_set.info()\n",
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c31fc65330497",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# drop the colum we don't need\n",
    "train_set_en.drop(['id', 'transcript', 'translation', 'processed'], axis=1, inplace=True)\n",
    "train_set_ja.drop(['id', 'transcript', 'translation', 'processed'], axis=1, inplace=True)\n",
    "train_set_ch.drop(['id', 'transcript', 'translation', 'processed'], axis=1, inplace=True)\n",
    "\n",
    "#check the dataframes\n",
    "train_set_en.info()\n",
    "train_set_ja.info()\n",
    "train_set_ch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0483e46de0b5a0b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# rename the column back_translation of train_set_en, train_set_ja, train_set_ch to transcript_en, transcript_ja, transcript_ch\n",
    "train_set_en.rename(columns={'back_translation':'transcript_en'}, inplace=True)\n",
    "train_set_ja.rename(columns={'back_translation':'transcript_ja'}, inplace=True)\n",
    "train_set_ch.rename(columns={'back_translation':'transcript_ch'}, inplace=True)\n",
    "\n",
    "# display the info of the dataframes\n",
    "train_set_en.info()\n",
    "train_set_ja.info()\n",
    "train_set_ch.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcb0d2c775166c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    " ## Calculating the length of each data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fce92ff337cd36",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate the length of each data sample in the train_set, val_set and test_set and add the length as a new column named length to the dataframes\n",
    "train_set['length'] = train_set['transcript'].apply(lambda x: len(x))\n",
    "val_set['length'] = val_set['transcript'].apply(lambda x: len(x))\n",
    "test_set['length'] = test_set['transcript'].apply(lambda x: len(x))\n",
    "\n",
    "# display the heads of the dataframes\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d503684e63f3943",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca111063ce72e44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7d1aedf73c5eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate the length of each data samples in the train_set_en, train_set_ja and train_set_ch and add the length as a new column named length to the dataframes\n",
    "train_set_en['length'] = train_set_en['transcript_en'].apply(lambda x: len(x))\n",
    "train_set_ja['length'] = train_set_ja['transcript_ja'].apply(lambda x: len(x))\n",
    "train_set_ch['length'] = train_set_ch['transcript_ch'].apply(lambda x: len(x))\n",
    "\n",
    "# display the heads of the dataframes\n",
    "train_set_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3098669cb330a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_set_ja.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e3696e15448be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_set_ch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc360ee9b2eae905",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Distribution based on length of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e8358426ac3bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make a function to plot the distribution of the length of the data samples in the train_set, val_set and test_set (boxplot and histogram)\n",
    "def plot_length_distribution(data, title):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    # sns.set(style=\"ticks\")\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    # plot the boxplot\n",
    "    # sns.boxplot(x='length', data=data, ax=ax1)\n",
    "    sns.boxplot(y='length', x='label', data=data, ax=ax1)\n",
    "    ax1.set_title('Boxplot')\n",
    "    \n",
    "    # plot the histogram\n",
    "    sns.histplot(x='length', data=data, ax=ax2)\n",
    "    ax2.set_title('Histogram')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6180b9db2e2d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the distribution of the length of the data samples in the train_set, val_set and test_set\n",
    "plot_length_distribution(train_set, 'Train Dataset Length Distribution')\n",
    "plot_length_distribution(val_set, 'Validation Dataset Length Distribution')\n",
    "plot_length_distribution(test_set, 'Test Dataset Length Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909211ee35011e2e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the distribution of the length of the data samples in the train_set_en, train_set_ja and train_set_ch\n",
    "plot_length_distribution(train_set_en, '(English Augmented) Train Dataset Length Distribution')\n",
    "plot_length_distribution(train_set_ja, '(Japanese Augmented) Train Dataset Length Distribution')\n",
    "plot_length_distribution(train_set_ch, '(Chinese Augmented) Train Dataset Length Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5914179101b8a6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Morphology Analyzer Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47456973424437e6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Installation of Mecab-ko-for-GoogleColab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14d1e92180aac2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if Mecab-ko-for-GoogleColab is installed. If not, install it.\n",
    "try:\n",
    "    from konlpy.tag import Mecab\n",
    "except:\n",
    "    print('Mecab-ko-for-GoogleColab is not installed. Installing...')\n",
    "    subprocess.check_call(['bash', './install_mecab-ko_on_colab190912.sh'])\n",
    "    print('Mecab-ko-for-GoogleColab installed.')\n",
    "\n",
    "\n",
    "# if not os.path.exists('/content/Mecab-ko-for-Google-Colab'):\n",
    "#     print('Installing Mecab-ko-for-Google-Colab...')\n",
    "#     !git clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd1217d8b6eba0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Testing MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b878896b2ff89e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Test MeCab and test morphological analysis on a sample sentence in Korean language (한국어)\n",
    "mecab = Mecab()\n",
    "print(mecab.morphs('한국어 형태소 분석기 테스트 중 입니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe87f5a9357f9cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# test pos tagging\n",
    "print(mecab.pos('한국어 형태소 분석기 테스트 중 입니다.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22351e1fae418bd5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72bd437f9aae3f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Dataset cleaning and purification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d91355582fc949",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to perform the cleaning parts\n",
    "def apply_replacement(src_df, replace_func):\n",
    "    ret_df = src_df\n",
    "    ret_df['transcript'] = ret_df['transcript'].apply(lambda x: replace_func(x))\n",
    "    return ret_df\n",
    "\n",
    "# remove the unwanted word and characters from the dataset\n",
    "def word_replace(x):\n",
    "    example_word_replace_list = {'o/': '',\n",
    "                                 'b/': '',\n",
    "                                 'n/': '',\n",
    "                                 '\\n': ' ',\n",
    "                                 'name': '',\n",
    "                                 'laughing': '',\n",
    "                                 'clearing': '',\n",
    "                                 'singing': '',\n",
    "                                 'applauding': ''}\n",
    "    for i in example_word_replace_list:\n",
    "        x = x.replace(i, example_word_replace_list[i])\n",
    "    return x\n",
    "\n",
    "# remove the special character from the transcripts\n",
    "def remove_special_sysmbols(sentence): \n",
    "    sentence = re.sub(r\"[-~=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]\", '', sentence)\n",
    "    return sentence\n",
    "\n",
    "# remove x and O from the transcripts\n",
    "def replace_x_o(sentence):\n",
    "    \n",
    "    # sentence = re.sub(r\"(o{2,})|(O{2,})|(\\ㅇ{2,})|(0{2,})|(x{2,})\", '' , sentence)\n",
    "    # sentence = re.sub(r\"x{2,}\", '' , sentence)\n",
    "    # sentence = re.sub(r\"0{2,}\", '' , sentence)\n",
    "    # sentence = re.sub(r\"ㅇ{2,}\", '' , sentence)\n",
    "    # sentence = re.sub(r\"O{2,}\", '' , sentence)\n",
    "    # sentence = re.sub(r\"o{2,}\", '' , sentence)\n",
    "    sentence = re.sub(r\"(o|O|\\ㅇ|0|x){2,}\", '' , sentence)\n",
    "    return sentence\n",
    "\n",
    "# remove the unwanted word and characters from the transcripts\n",
    "def nline_replace(x):\n",
    "    example_word_replace_list = {'\\n' : ' '}\n",
    "    for i in example_word_replace_list:\n",
    "        x = x.replace(i, example_word_replace_list[i])\n",
    "    return x\n",
    "\n",
    "# remove extra whote space\n",
    "def remove_extra_white_spaces(text):\n",
    "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
    "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
    "    return without_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432cbbfb78edd02",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Clear the train_set using the function defined above\n",
    "train_set['transcript_clean'] = train_set['transcript'].apply(lambda x: word_replace(x))\n",
    "train_set['transcript_clean'] = train_set['transcript_clean'].apply(lambda x: remove_special_sysmbols(x))\n",
    "train_set['transcript_clean'] = train_set['transcript_clean'].apply(lambda x: replace_x_o(x))\n",
    "train_set['transcript_clean'] = train_set['transcript_clean'].apply(lambda x: nline_replace(x))\n",
    "train_set['transcript_clean'] = train_set['transcript_clean'].apply(lambda x: remove_extra_white_spaces(x))\n",
    "train_set['length_transcript_clean'] = train_set['transcript_clean'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91dafce83b1d595",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Clear the val_set using the function defined above\n",
    "val_set['transcript_clean'] = val_set['transcript'].apply(lambda x: word_replace(x))\n",
    "val_set['transcript_clean'] = val_set['transcript_clean'].apply(lambda x: remove_special_sysmbols(x))\n",
    "val_set['transcript_clean'] = val_set['transcript_clean'].apply(lambda x: replace_x_o(x))\n",
    "val_set['transcript_clean'] = val_set['transcript_clean'].apply(lambda x: nline_replace(x))\n",
    "val_set['transcript_clean'] = val_set['transcript_clean'].apply(lambda x: remove_extra_white_spaces(x))\n",
    "val_set['length_transcript_clean'] = val_set['transcript_clean'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811fb21d561bef4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Clear the test_set using the function defined above\n",
    "test_set['transcript_clean'] = test_set['transcript'].apply(lambda x: word_replace(x))\n",
    "test_set['transcript_clean'] = test_set['transcript_clean'].apply(lambda x: remove_special_sysmbols(x))\n",
    "test_set['transcript_clean'] = test_set['transcript_clean'].apply(lambda x: replace_x_o(x))\n",
    "test_set['transcript_clean'] = test_set['transcript_clean'].apply(lambda x: nline_replace(x))\n",
    "test_set['transcript_clean'] = test_set['transcript_clean'].apply(lambda x: remove_extra_white_spaces(x))\n",
    "test_set['length_transcript_clean'] = test_set['transcript_clean'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b98a337c16cb1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Clear the train_set_en using the function defined above\n",
    "train_set_en['transcript_clean_en'] = train_set_en['transcript_en'].apply(lambda x: word_replace(x))\n",
    "train_set_en['transcript_clean_en'] = train_set_en['transcript_clean_en'].apply(lambda x: remove_special_sysmbols(x))\n",
    "train_set_en['transcript_clean_en'] = train_set_en['transcript_clean_en'].apply(lambda x: replace_x_o(x))\n",
    "train_set_en['transcript_clean_en'] = train_set_en['transcript_clean_en'].apply(lambda x: nline_replace(x))\n",
    "train_set_en['transcript_clean_en'] = train_set_en['transcript_clean_en'].apply(lambda x: remove_extra_white_spaces(x))\n",
    "train_set_en['length_transcript_clean_en'] = train_set_en['transcript_clean_en'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b7753b7500a82d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Clear the train_set_ja using the function defined above\n",
    "train_set_ja['transcript_clean_ja'] = train_set_ja['transcript_ja'].apply(lambda x: word_replace(x))\n",
    "train_set_ja['transcript_clean_ja'] = train_set_ja['transcript_clean_ja'].apply(lambda x: remove_special_sysmbols(x))\n",
    "train_set_ja['transcript_clean_ja'] = train_set_ja['transcript_clean_ja'].apply(lambda x: replace_x_o(x))\n",
    "train_set_ja['transcript_clean_ja'] = train_set_ja['transcript_clean_ja'].apply(lambda x: nline_replace(x))\n",
    "train_set_ja['transcript_clean_ja'] = train_set_ja['transcript_clean_ja'].apply(lambda x: remove_extra_white_spaces(x))\n",
    "train_set_ja['length_transcript_clean_ja'] = train_set_ja['transcript_clean_ja'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f65723736cee8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Clear the train_set_ch using the function defined above\n",
    "train_set_ch['transcript_clean_ch'] = train_set_ch['transcript_ch'].apply(lambda x: word_replace(x))\n",
    "train_set_ch['transcript_clean_ch'] = train_set_ch['transcript_clean_ch'].apply(lambda x: remove_special_sysmbols(x))\n",
    "train_set_ch['transcript_clean_ch'] = train_set_ch['transcript_clean_ch'].apply(lambda x: replace_x_o(x))\n",
    "train_set_ch['transcript_clean_ch'] = train_set_ch['transcript_clean_ch'].apply(lambda x: nline_replace(x))\n",
    "train_set_ch['transcript_clean_ch'] = train_set_ch['transcript_clean_ch'].apply(lambda x: remove_extra_white_spaces(x))\n",
    "train_set_ch['length_transcript_clean_ch'] = train_set_ch['transcript_clean_ch'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375993ca98ba0d49",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ba27a2d4741a4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "val_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c5a24354b9ebc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21970c82043fb01",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa860f46f27ffbc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set_ja.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d636e9e1a9a88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set_ch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab58353be20eee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Remove the Korean stop words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145543557b661f83",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import the Korean stop words\n",
    "# stop_words = pd.read_csv('korean_stopwords.csv')\n",
    "# stop_words = stop_words['stopwords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5226758cfe00dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # remove the Korean stop words from the train_set\n",
    "# train_set['transcript_clean'] = train_set['transcript_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "# train_set['length_transcript_clean'] = train_set['transcript_clean'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7ae4c3bb27c71",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## remove the stop word\n",
    "stopwords = [\"을\", \"를\", \"이\", \"가\", \"ㅡ\", \"은\", \"는\", \"XXX\", \"xxx\", \"어요\", \"아니\", \"입니다\", \"에서\", \"니까\", \"으로\",\n",
    "             \"근데\", \"습니다\", \"습니까\", \"저희\", \"합니다\", \"하고\", \"싶어요\", \"있는\", \"있습니다\", \"싶습니다\", \"그냥\",\n",
    "             \"고요\", \"에요\", \"예요\", \"으시\", \"그래서\"]\n",
    "\n",
    "# open and read the file containing comprehensive stopwords \n",
    "# stopwords_all = open(\"stopwords-ko.txt\").readlines()\n",
    "\n",
    "# function to remove the stop word from the train and test dataframe\n",
    "def get_model_input(_words):\n",
    "    global stopwords\n",
    "    _words = [x for x in _words if x[0] not in stopwords]\n",
    "    _words = [x for x in _words if x[:-1] not in stopwords]\n",
    "\n",
    "    for i in range(len(_words)-1):\n",
    "        yield _words[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485bd763b3c0654",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_corpus(df):\n",
    "    corpus = []\n",
    "    for lwords in df:    \n",
    "        temp = []\n",
    "        for x in get_model_input(lwords):\n",
    "            if len(x) != 1:\n",
    "                temp.append(\"{}\".format(x))\n",
    "        corpus.append(\" \".join(temp))\n",
    "    return corpus        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd9bbd17301506",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "train_set_corpus = get_corpus([(mecab.morphs(x)) for x in train_set['transcript_clean']])\n",
    "val_set_corpus = get_corpus([(mecab.morphs(x)) for x in val_set['transcript_clean']])\n",
    "test_set_corpus = get_corpus([(mecab.morphs(x)) for x in test_set['transcript_clean']])\n",
    "\n",
    "train_set_en_corpus = get_corpus([(mecab.morphs(x)) for x in train_set_en['transcript_clean_en']])\n",
    "train_set_ja_corpus = get_corpus([(mecab.morphs(x)) for x in train_set_ja['transcript_clean_ja']])\n",
    "train_set_ch_corpus = get_corpus([(mecab.morphs(x)) for x in train_set_ch['transcript_clean_ch']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c0d7b61f50c9d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# adding the corpus to the dataframe\n",
    "train_set['corpus'] = train_set_corpus\n",
    "val_set['corpus'] = val_set_corpus\n",
    "test_set['corpus'] = test_set_corpus\n",
    "\n",
    "# adding the corpus to the dataframe\n",
    "train_set_en['corpus_en'] = train_set_en_corpus\n",
    "train_set_ja['corpus_ja'] = train_set_ja_corpus\n",
    "train_set_ch['corpus_ch'] = train_set_ch_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a5f39b1cbe015",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# add the length of the corpus to the dataframe\n",
    "train_set['length_corpus'] = train_set['corpus'].apply(lambda x: len(x))\n",
    "val_set['length_corpus'] = val_set['corpus'].apply(lambda x: len(x))\n",
    "test_set['length_corpus'] = test_set['corpus'].apply(lambda x: len(x))\n",
    "\n",
    "# add the length of the corpus to the dataframe\n",
    "train_set_en['length_corpus_en'] = train_set_en['corpus_en'].apply(lambda x: len(x))\n",
    "train_set_ja['length_corpus_ja'] = train_set_ja['corpus_ja'].apply(lambda x: len(x))\n",
    "train_set_ch['length_corpus_ch'] = train_set_ch['corpus_ch'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4fd72ade1cad2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893de1e5705bb527",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "val_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13cfc822f78a85a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes   \n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7fca3fc56606f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab625ca3c203a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set_ja.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7045a2b73a6d814d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# display the heads of the dataframes\n",
    "train_set_ch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ffbd1a87becfa6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# save the train_set, val_set and test_set to csv files\n",
    "train_set.to_csv('train_set_clean.csv', index=False)\n",
    "val_set.to_csv('val_set_clean.csv', index=False)\n",
    "test_set.to_csv('test_set_clean.csv', index=False)\n",
    "\n",
    "# save the train_set_en, train_set_ja and train_set_ch to csv files\n",
    "train_set_en.to_csv('train_set_en_clean.csv', index=False)\n",
    "train_set_ja.to_csv('train_set_ja_clean.csv', index=False)\n",
    "train_set_ch.to_csv('train_set_ch_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea6a6393b5f6c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the word cloud of the train_set corpus with Korean font \n",
    "wordcloud = WordCloud(font_path='NanumGothic.ttf', width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                min_font_size = 10).generate(' '.join(train_set['corpus']))\n",
    "\n",
    "# plot the WordCloud image\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f4dd288cc81b4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d6062ed16881344",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Vectorization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cef9205169fea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_dataset(df_train, df_test, df_validation):\n",
    "    # Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "    tfidf = TfidfVectorizer(# analyzer='word', # default='word'\n",
    "                            ngram_range=(1, 3), #(2, 6), # 3,6\n",
    "                            max_df=0.5, #ignoring terms that have a document frequency higher than 0.5\n",
    "                            # min_df=2, # 10\n",
    "                            max_features=2000, #300, 500, 10000 (this will limit the vocabulary)\n",
    "                            sublinear_tf=True, #replaces tf with 1 + log(tf), twenty occurrences of a term in a document\n",
    "                                                #does not represent twenty times the significance of a single occurrence\n",
    "                            use_idf=True\n",
    "    )\n",
    "\n",
    "    #Converting the sparse matrix into an array\n",
    "    #We then apply the toarray function to convert the sparse matrix into an array.\n",
    "    X_train = tfidf.fit_transform(df_train['corpus']).toarray()\n",
    "    X_test = tfidf.transform(df_test['corpus']).toarray()\n",
    "    X_validation = tfidf.fit_transform(df_validation['corpus']).toarray()\n",
    "\n",
    "    y_train, y_validation, y_test = df_train['label'], df_validation['label'], df_test['label']\n",
    "    \n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe4127a802ddd3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# vectorize the dataset\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = vectorize_dataset(train_set, test_set, val_set)\n",
    "\n",
    "#set the evaluation set for early stop models\n",
    "eval_set = [(X_validation, y_validation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08ba76b9c1e0c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Training ML models with imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c90d996e05fd5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## TRAINING CODE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8236e2cfbce4d06",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # function to train the ML models\n",
    "# def train_ml_model(X_train, X_validation, X_test, y_train, y_validation, y_test, model):\n",
    "#     start = timer()\n",
    "#     model[1].fit(X_train, y_train)\n",
    "#     end = timer()\n",
    "#     training_time = end - start\n",
    "#     y_pred = model[1].predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred, average='macro')\n",
    "#     recall = recall_score(y_test, y_pred, average='macro')\n",
    "#     f1 = f1_score(y_test, y_pred, average='macro')\n",
    "#     f2 = fbeta_score(y_test, y_pred, beta=2.0, average='macro')\n",
    "#     roc_auc = roc_auc_score(y_test, y_pred, average='macro')\n",
    "#     matthews_corrcoef = matthews_corrcoef(y_test, y_pred)\n",
    "#     cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     cr = classification_report(y_test, y_pred)\n",
    "#     return training_time, accuracy, precision, recall, f1, f2, roc_auc, matthews_corrcoef, cohen_kappa, cm, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85951681a01e254",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def train_ml_model(X_train, X_validation, X_test, y_train, y_validation, y_test, model):\n",
    "#     # start the timer\n",
    "#     start = timer()\n",
    "#     \n",
    "#     # fit the model\n",
    "#     model.fit(X_train, y_train)\n",
    "#     \n",
    "#     # make predictions for test data\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     \n",
    "#     # stop the timer\n",
    "#     end = timer()\n",
    "#     \n",
    "#     # calculate the training time\n",
    "#     training_time = end - start\n",
    "#     \n",
    "#     # calculate the accuracy score\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     \n",
    "#     # calculate the precision score\n",
    "#     precision = precision_score(y_test, y_pred, average='macro')\n",
    "#     \n",
    "#     # calculate the recall score\n",
    "#     recall = recall_score(y_test, y_pred, average='macro')\n",
    "#     \n",
    "#     # calculate the f1 score\n",
    "#     f1 = f1_score(y_test, y_pred, average='macro')\n",
    "#     \n",
    "#     # calculate the f2 score\n",
    "#     f2 = fbeta_score(y_test, y_pred, average='macro', beta=2.0)\n",
    "#     \n",
    "#     # calculate the roc auc score\n",
    "#     roc_auc = roc_auc_score(y_test, y_pred, average='macro', multi_class='ovo')\n",
    "#     \n",
    "#     # calculate the matthews correlation coefficient\n",
    "#     matthews_corrcoef = matthews_corrcoef(y_test, y_pred)\n",
    "#     \n",
    "#     # calculate the cohen kappa score\n",
    "#     cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "#     \n",
    "#     # calculate the confusion matrix\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     \n",
    "#     # calculate the classification report\n",
    "#     cr = classification_report(y_test, y_pred)\n",
    "#     \n",
    "#     # return the results\n",
    "#     return training_time, accuracy, precision, recall, f1, f2, roc_auc, matthews_corrcoef, cohen_kappa, cm, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fcdd51278e234",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # function to print the results\n",
    "# def print_results(training_time, accuracy, precision, recall, f1, f2, roc_auc, matthews_corrcoef, cohen_kappa, cm, cr):\n",
    "#     print('Training Time: ', training_time)\n",
    "#     print('Accuracy: ', accuracy)\n",
    "#     print('Precision: ', precision)\n",
    "#     print('Recall: ', recall)\n",
    "#     print('F1: ', f1)\n",
    "#     print('F2: ', f2)\n",
    "#     print('ROC AUC: ', roc_auc)\n",
    "#     print('Matthews Corrcoef: ', matthews_corrcoef)\n",
    "#     print('Cohen Kappa: ', cohen_kappa)\n",
    "#     print('Confusion Matrix: \\n', cm)\n",
    "#     print('Classification Report: \\n', cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c1c6345a9f8bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # define the ML models\n",
    "# models = [\n",
    "#     ('MultinomialNB', MultinomialNB()),\n",
    "#     ('GaussianNB', GaussianNB()),\n",
    "#     ('RandomForestClassifier', RandomForestClassifier()),\n",
    "#     ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "#     ('LogisticRegression', LogisticRegression()),\n",
    "#     ('XGBClassifier', XGBClassifier()),\n",
    "#     ('LGBMClassifier', LGBMClassifier()),\n",
    "#     ('SVC', SVC())\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4494a38488bbef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # train the ML models considering 'MultinomialNB' object is not subscriptable\n",
    "# for name, model in models:\n",
    "#     print('Training ', name, '...')\n",
    "#     training_time, accuracy, precision, recall, f1, f2, roc_auc, matthews_corrcoef, cohen_kappa, cm, cr = train_ml_model(X_train, X_validation, X_test, y_train, y_validation, y_test, model)\n",
    "#     print_results(training_time, accuracy, precision, recall, f1, f2, roc_auc, matthews_corrcoef, cohen_kappa, cm, cr)\n",
    "#     print('Training ', name, 'completed.')\n",
    "#     print('--------------------------------------------------')\n",
    "# \n",
    "# # for name, model in models:\n",
    "# #     print('Training ', name, '...')\n",
    "# #     training_time, accuracy, precision, recall, f1, f2, roc_auc, matthews_corrcoef, cohen_kappa, cm, cr = train_ml_model(X_train, X_validation, X_test, y_train, y_validation, y_test, model)\n",
    "# #     print_results(training_time, accuracy, precision, recall, f1, f2, roc_auc, matthews_corrcoef, cohen_kappa, cm, cr)\n",
    "# #     print('Training ', name, 'completed.')\n",
    "# #     print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d29f384d6ebbcb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # function to plot the confusion matrix\n",
    "# def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "#     # plot the confusion matrix\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     \n",
    "#     # plot the ticks\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "#     \n",
    "#     # plot the text\n",
    "#     fmt = 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#             plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#             \n",
    "#     # plot the labels\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55670c0cc01cef88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## TRAINING CODE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2307003a2e8354",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def get_metrics(y_test, y_test_pred, y_test_proba, threshold=0.5):\n",
    "#     # y_pred_class = y_test_proba > threshold\n",
    "#     y_pred_class = y_test_pred\n",
    "# \n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, y_pred_class).ravel()\n",
    "# \n",
    "#     true_positive_rate = tp / (tp + fn)\n",
    "#     true_negative_rate = tn / (tn + fp)\n",
    "#     positive_predictive_value = tp / (tp + fp)\n",
    "#     negative_predictive_value = tn / (tn + fn)\n",
    "#     false_positive_rate = fp / (fp + tn)\n",
    "#     false_negative_rate = fn / (tp + fn)\n",
    "#     false_discovery_rate = fp / (tp + fp)\n",
    "# \n",
    "#     scores = {'Accuracy': accuracy_score(y_test, y_pred_class),\n",
    "#               'Precision': precision_score(y_test, y_pred_class),\n",
    "#               'Recall': recall_score(y_test, y_pred_class),\n",
    "#               'F1_score': f1_score(y_test, y_pred_class),\n",
    "#               'F05_score': fbeta_score(y_test, y_pred_class, beta=0.5),\n",
    "#               'F2_score': fbeta_score(y_test, y_pred_class, beta=2),\n",
    "#               'Roc auc score': roc_auc_score(y_test, y_test_proba),\n",
    "#               'Matthews_corrcoef': matthews_corrcoef(y_test, y_pred_class),\n",
    "#               'Cohen_kappa': cohen_kappa_score(y_test, y_pred_class),\n",
    "#               'True_positive_rate': true_positive_rate,\n",
    "#               'True_negative_rate': true_negative_rate,\n",
    "#               'Positive_predictive_value': positive_predictive_value,\n",
    "#               'Negative_predictive_value': negative_predictive_value,\n",
    "#               'False_positive_rate': false_positive_rate,\n",
    "#               'False_negative_rate': false_negative_rate,\n",
    "#               'False_discovery_rate': false_discovery_rate,\n",
    "#               }\n",
    "# \n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4da8d500b77e58",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Define the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed697376cd5fdea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # define the ML models\n",
    "# def define_models():\n",
    "#     models = [] #list to save the initiated models\n",
    "#     \n",
    "# #     # Gaussian Naive Bayes\n",
    "# #     # gnb assumes them to be continuous\n",
    "# #     gnb = GaussianNB()\n",
    "# \n",
    "# #     # Mltinomial Naive Bayes\n",
    "# #     # nb assumes the features are discrete\n",
    "# #     mnb = MultinomialNB()\n",
    "# \n",
    "# #     #logistic regression\n",
    "# #     lr = LogisticRegression(\n",
    "# #         # C=10,# random_state=1234\n",
    "# #     )\n",
    "# \n",
    "# #     #Decision Tree\n",
    "#     dt = DecisionTreeClassifier(\n",
    "#         # max_depth=10, \n",
    "#         # random_state=1234\n",
    "#     )\n",
    "# \n",
    "#     #Random Forest\n",
    "#     rf = RandomForestClassifier(\n",
    "#         # n_estimators=100,\n",
    "#         # max_depth=20,\n",
    "#         # max_features=0.06,\n",
    "#         # n_jobs=6,\n",
    "#         # random_state=1234\n",
    "#     )\n",
    "# \n",
    "#     #XGBoost\n",
    "#     xgb = XGBClassifier(\n",
    "#         early_stopping_rounds=10,\n",
    "#         verbosity=2,\n",
    "#         # n_estimators=2000,\n",
    "#         # tree_method='hist',\n",
    "#         # subsample=0.67,\n",
    "#         # colsample_level=0.06,\n",
    "#         # n_jobs=6,\n",
    "#         # random_state=1234\n",
    "#     )\n",
    "# \n",
    "#     #LightGBM\n",
    "#     lgbm = LGBMClassifier(\n",
    "#         early_stopping_rounds=10,\n",
    "#         verbosity=2,\n",
    "#         # boost_from_average=False\n",
    "#         # num_leaves=64,\n",
    "#         # n_estimators=2000,\n",
    "#         # feature_fraction=0.06,\n",
    "#         # bagging_fraction=0.67,\n",
    "#         # bagging_freq=1,\n",
    "#         # n_jobs=6,\n",
    "#         # random_state=1234\n",
    "#     )\n",
    "#     \n",
    "#     #add the models in the list\n",
    "#     models = [dt, rf, xgb, lgbm]\n",
    "#     \n",
    "#     # #to specify which of our models require early stopping within the .fit() method.\n",
    "#     es_models = ['XGBClassifier', 'LGBMClassifier']\n",
    "#     \n",
    "#     return models, es_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2423798dc1354e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Train the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975908c8030f62c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # train the ML models\n",
    "# def train_models(models, es_models, X_train, X_test, y_train, y_test, eval_set):\n",
    "#     # dictionary to save the results\n",
    "#     results = {}\n",
    "#     \n",
    "#     # loop through the models\n",
    "#     for model in models:\n",
    "#         # get the name of the model\n",
    "#         name = model.__class__.__name__\n",
    "#         \n",
    "#         # check if the model requires early stopping\n",
    "#         if name in es_models:\n",
    "#             # fit the model\n",
    "#             model.fit(X_train, y_train, eval_set=eval_set)\n",
    "#         else:\n",
    "#             # fit the model\n",
    "#             model.fit(X_train, y_train)\n",
    "#         \n",
    "#         # make predictions for test data\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         \n",
    "#         # make predictions for test data\n",
    "#         y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "#         \n",
    "#         # get the metrics\n",
    "#         scores = get_metrics(y_test, y_pred, y_pred_proba)\n",
    "#         \n",
    "#         # add the results to the dictionary\n",
    "#         results[name] = scores\n",
    "#         \n",
    "#         # print the results\n",
    "#         print(name, 'completed.')\n",
    "#         print('--------------------------------------------------')\n",
    "#         metric_scores = get_metrics(y_test, y_pred, y_pred_proba)\n",
    "#         for metric_name, score in metric_scores.items():\n",
    "#             print('{} :{}'.format(metric_name, score))\n",
    "#         print('#'*80)\n",
    "#         \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec425c1b99a33a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Train the ML models\n",
    "# models, es_models = define_models()\n",
    "# results = train_models(models, es_models, X_train, X_test, y_train, y_test, eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304a4814e5bf275",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # function to print the results\n",
    "# def print_results(results):\n",
    "#     for name, scores in results.items():\n",
    "#         print(name, 'results')\n",
    "#         print('--------------------------------------------------')\n",
    "#         print('Accuracy: ', scores['Accuracy'])\n",
    "#         print('Precision: ', scores['Precision'])\n",
    "#         print('Recall: ', scores['Recall'])\n",
    "#         print('F1: ', scores['F1_score'])\n",
    "#         print('F0.5: ', scores['F05_score'])\n",
    "#         print('F2: ', scores['F2_score'])\n",
    "#         print('ROC AUC: ', scores['Roc auc score'])\n",
    "#         print('Matthews Corrcoef: ', scores['Matthews_corrcoef'])\n",
    "#         print('Cohen Kappa: ', scores['Cohen_kappa'])\n",
    "#         print('True Positive Rate: ', scores['True_positive_rate'])\n",
    "#         print('True Negative Rate: ', scores['True_negative_rate'])\n",
    "#         print('Positive Predictive Value: ', scores['Positive_predictive_value'])\n",
    "#         print('Negative Predictive Value: ', scores['Negative_predictive_value'])\n",
    "#         print('False Positive Rate: ', scores['False_positive_rate'])\n",
    "#         print('False Negative Rate: ', scores['False_negative_rate'])\n",
    "#         print('False Discovery Rate: ', scores['False_discovery_rate'])\n",
    "#         print('--------------------------------------------------')\n",
    "#         \n",
    "# # print the results\n",
    "# print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69849d9a1b0ddedc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # function to plot the confusion matrix\n",
    "# def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "#     # plot the confusion matrix\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     \n",
    "#     # plot the ticks\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "#     \n",
    "#     # plot the text\n",
    "#     fmt = 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#             plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#             \n",
    "#     # plot the labels\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae833a5071549e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # plot the confusion matrix\n",
    "# plot_confusion_matrix(results['DecisionTreeClassifier']['Confusion Matrix'], classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5503bad0d8fc34",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# TRAINING CODE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8b7c408e89643",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_test_pred, y_test_proba, threshold=0.5):\n",
    "    # y_pred_class = y_test_proba > threshold\n",
    "    y_pred_class = y_test_pred\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_class).ravel()\n",
    "\n",
    "    true_positive_rate = tp / (tp + fn)\n",
    "    true_negative_rate = tn / (tn + fp)\n",
    "    positive_predictive_value = tp / (tp + fp)\n",
    "    negative_predictive_value = tn / (tn + fn)\n",
    "    false_positive_rate = fp / (fp + tn)\n",
    "    false_negative_rate = fn / (tp + fn)\n",
    "    false_discovery_rate = fp / (tp + fp)\n",
    "\n",
    "    scores = {'Accuracy': accuracy_score(y_test, y_pred_class),\n",
    "              'Precision': precision_score(y_test, y_pred_class),\n",
    "              'Recall': recall_score(y_test, y_pred_class),\n",
    "              'F1_score': f1_score(y_test, y_pred_class),\n",
    "              'F05_score': fbeta_score(y_test, y_pred_class, beta=0.5),\n",
    "              'F2_score': fbeta_score(y_test, y_pred_class, beta=2),\n",
    "              'Roc auc score': roc_auc_score(y_test, y_test_proba),\n",
    "              'Matthews_corrcoef': matthews_corrcoef(y_test, y_pred_class),\n",
    "              'Cohen_kappa': cohen_kappa_score(y_test, y_pred_class),\n",
    "              'True_positive_rate': true_positive_rate,\n",
    "              'True_negative_rate': true_negative_rate,\n",
    "              'Positive_predictive_value': positive_predictive_value,\n",
    "              'Negative_predictive_value': negative_predictive_value,\n",
    "              'False_positive_rate': false_positive_rate,\n",
    "              'False_negative_rate': false_negative_rate,\n",
    "              'False_discovery_rate': false_discovery_rate,\n",
    "              }\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0502752c2880eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Define the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a1bc7c71625e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define the ML models\n",
    "def define_models():\n",
    "    models = [] #list to save the initiated models\n",
    "    \n",
    "#     # Gaussian Naive Bayes\n",
    "#     # gnb assumes them to be continuous\n",
    "#     gnb = GaussianNB()\n",
    "\n",
    "#     # Mltinomial Naive Bayes\n",
    "#     # nb assumes the features are discrete\n",
    "#     mnb = MultinomialNB()\n",
    "\n",
    "#     #logistic regression\n",
    "#     lr = LogisticRegression(\n",
    "#         # C=10,# random_state=1234\n",
    "#     )\n",
    "\n",
    "#     #Decision Tree\n",
    "    dt = DecisionTreeClassifier(\n",
    "        # max_depth=10, \n",
    "        # random_state=1234\n",
    "    )\n",
    "\n",
    "    #Random Forest\n",
    "    rf = RandomForestClassifier(\n",
    "        # n_estimators=100,\n",
    "        # max_depth=20,\n",
    "        # max_features=0.06,\n",
    "        # n_jobs=6,\n",
    "        # random_state=1234\n",
    "    )\n",
    "\n",
    "    #XGBoost\n",
    "    xgb = XGBClassifier(\n",
    "        early_stopping_rounds=10,\n",
    "        verbosity=2,\n",
    "        # n_estimators=2000,\n",
    "        # tree_method='hist',\n",
    "        # subsample=0.67,\n",
    "        # colsample_level=0.06,\n",
    "        # n_jobs=6,\n",
    "        # random_state=1234\n",
    "    )\n",
    "\n",
    "    #LightGBM\n",
    "    lgbm = LGBMClassifier(\n",
    "        early_stopping_rounds=10,\n",
    "        verbosity=2,\n",
    "        # boost_from_average=False\n",
    "        # num_leaves=64,\n",
    "        # n_estimators=2000,\n",
    "        # feature_fraction=0.06,\n",
    "        # bagging_fraction=0.67,\n",
    "        # bagging_freq=1,\n",
    "        # n_jobs=6,\n",
    "        # random_state=1234\n",
    "    )\n",
    "    \n",
    "    #add the models in the list\n",
    "    models = [dt, rf, xgb, lgbm]\n",
    "    \n",
    "    # #to specify which of our models require early stopping within the .fit() method.\n",
    "    es_models = ['XGBClassifier', 'LGBMClassifier']\n",
    "    \n",
    "    return models, es_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555aff17accd7aa5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Train the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59ee07b294ebb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Setting up our results dataframe\n",
    "df_results = pd.DataFrame(columns=['Model', 'F1_score', 'Precision', 'Recall', 'ROC AUC', 'Accuracy', 'Training time', 'Test time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c6341bf7c771f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#  Function to plot the confusion matrix\n",
    "# https://github.com/prateeksawhney97/MNIST-Classification-Multinomial-vs-Gaussian-Naive-Bayes/blob/master/MNIST%20Classification.ipynb\n",
    "\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72530cc2d63b1cf1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to train the ML models\n",
    "def train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling=\"\", bt_name=\"\"):   \n",
    "    #retrievce the models' name\n",
    "    model_names = [i.__class__.__name__ for i in models]\n",
    "    #set the number of classes for the confusion matrix\n",
    "    classes_labels = np.arange(2)\n",
    "    #name for oversampling method\n",
    "    over_name = ''\n",
    "\n",
    "    # Dataset shape\n",
    "    print(\"-- Dataset shape --\")\n",
    "    print('Original dataset shape')\n",
    "    print(Counter(y_train))#Counting the samples in training set\n",
    "    \n",
    "    # fit and apply the transform to the training data_set is set(dataset oversampling)\n",
    "    oversample = sampling\n",
    "    if oversample:\n",
    "        over_name = oversample.__class__.__name__\n",
    "        X_train_over, y_train_over = oversample.fit_resample(X_train, y_train) #resampling the dataset\n",
    "        X_train= X_train_over # assign new sample to trainset, text\n",
    "        y_train = y_train_over #assign new sample to trainset, label\n",
    "        print('Resampled dataset shape %s' % Counter(y_train))\n",
    "    \n",
    "    print('-'*50)  \n",
    "    start = timer()\n",
    "    #Train each of our candidate models\n",
    "    for m, n in zip(models, model_names):\n",
    "        # print('-'*50)\n",
    "        \n",
    "        train_time = 0\n",
    "        test_time = 0\n",
    "        train_predict_time = 0\n",
    "        test_predict_time = 0\n",
    "\n",
    "        print(\"\\n\"+n+\"_\"+over_name+bt_name) #print the model name\n",
    "        if n in es_models:\n",
    "            t0 = time()\n",
    "            m.fit(X_train, y_train, \n",
    "                  eval_set = eval_set, \n",
    "                  # early_stopping_rounds=15,\n",
    "                  # verbose=0\n",
    "                 )\n",
    "            train_time = time() - t0\n",
    "        else:\n",
    "            t0 = time()\n",
    "            m.fit(X_train, y_train)\n",
    "            train_time = time() - t0\n",
    "\n",
    "        print(f\"\\nTraining time: {round(train_time, 3)}sec\")\n",
    "\n",
    "        #Model training prediction\n",
    "        t0 = time()\n",
    "        train_score = m.score(X_train, y_train)\n",
    "        train_predict_time = time() - t0\n",
    "        print(f\"Prediction time (train): {round(train_predict_time, 3)}sec\")\n",
    "\n",
    "        #Model test prediction\n",
    "        t0 = time()\n",
    "        test_score = m.score(X_test, y_test)\n",
    "        test_predict_time = time() - t0\n",
    "        print(f\"Prediction time (test): {round(test_predict_time, 3)}sec\")\n",
    "\n",
    "        #Check for Overfitting\n",
    "        print('\\n-- Check for Overfitting --')\n",
    "        #print the scores on training and test set\n",
    "        print('Train set score: {:.4f} sec '.format(train_score))\n",
    "        print('Test set score: {:.4f} sec'.format(test_score))\n",
    "\n",
    "        # Evaluate the trained model on the test set\n",
    "        '''\n",
    "        Use 'predict' for binary or multi-class classification problems when you want to get\n",
    "        the predicted class label(s) for input data.\n",
    "        '''\n",
    "        t0 = time()\n",
    "        predicted = m.predict(X_test) #return the label of the test set samples (actual class)\n",
    "        test_time = time() - t0\n",
    "        print(f\"Prediction time (test): {round(test_time, 3)}sec\")\n",
    "        # print('f1 score____ :', f1_score(y_test, predicted))\n",
    "\n",
    "        # accuracy of the model on the test set\n",
    "        # test_acc0 = np.mean(predicted == y_test)\n",
    "        # print('Model Accuracy on test set (Mean method) {:.4f} sec'.format(test_acc0))\n",
    "        # # accuracy of the model on the test set\n",
    "        # test_acc1 = accuracy_score(predicted, y_test)\n",
    "        # print('Model Accuracy on test set (acc_score method) {:.4f} sec'.format(test_acc1))\n",
    "        # test_acc2 = accuracy_score(y_test, predicted)\n",
    "        # print('Model Accuracy on test set (acc_score method_reverse): {0:0.4f} sec'.format(test_acc2))\n",
    "\n",
    "        # classification report\n",
    "        print(\"\\n-- classification Report --\")\n",
    "        print(classification_report(y_test, predicted)) \n",
    "\n",
    "        #Confusion-matrix\n",
    "        '''\n",
    "        Print the Confusion Matrix and slice it into four pieces\n",
    "        '''\n",
    "        cm = confusion_matrix(y_test, predicted)\n",
    "        print('\\n-- Confusion matrix --\\n', cm)\n",
    "        print('True Positives(TP) = ', cm[0,0])\n",
    "        print('True Negatives(TN) = ', cm[1,1])\n",
    "        print('False Positives(FP) = ', cm[0,1])\n",
    "        print('False Negatives(FN) = ', cm[1,0])\n",
    "\n",
    "        # plot_confusion_matrix(cm,\n",
    "        #                       classes=classes_labels,\n",
    "        #                       normalize=False,\n",
    "        #                       title=\"Consfusion Matrix\",\n",
    "        #                       cmap=plt.cm.Blues\n",
    "        #                      )\n",
    "        # print('-'*80)\n",
    "\n",
    "        '''\n",
    "        Use 'predict_proba' for binary or multi-class classification problems when you want to get\n",
    "        the probability estimates for each possible class label.\n",
    "        '''\n",
    "        t0 = time()\n",
    "        y_test_proba = m.predict_proba(X_test)[:, 1] #return the probability estimates for each possible class label (the class probabilities)\n",
    "        test_time = time() - t0\n",
    "        \n",
    "        print('\\n-- Metrics scores --\\n')\n",
    "        metric_scores = get_metrics(y_test, predicted, y_test_proba)\n",
    "        for metric_name, score in metric_scores.items():\n",
    "            print('{} :{}'.format(metric_name, score))\n",
    "        print('#'*80)\n",
    "        \n",
    "        #save the results in the dataframe df_results    \n",
    "        df_results.loc[len(df_results.index)] = [n+\"_\"+over_name+bt_name, metric_scores.get(\"F1_score\"), metric_scores.get(\"Precision\"), metric_scores.get(\"Recall\"), metric_scores.get(\"Roc auc score\"), test_score, train_time, test_time]\n",
    "        del m #delete the model\n",
    "\n",
    "    train_test_time = timer() - start\n",
    "    print('Training and testing time of all models {:.4f} seconds'.format(train_test_time))\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2de6be856a8f4b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#define the models\n",
    "models, es_models = define_models()\n",
    "\n",
    "#train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9c911974934e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5c530a9348064",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training model with resampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6de656066711f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import the train_set, test_set, val_set\n",
    "train_set = pd.read_csv('train_set_clean.csv')\n",
    "test_set = pd.read_csv('test_set_clean.csv')\n",
    "val_set = pd.read_csv('val_set_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977cf4094e779f02",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_class_distribution(train_set, 'Train Dataset Class Distribution')\n",
    "plot_class_distribution(test_set, 'Train Dataset Class Distribution')\n",
    "plot_class_distribution(val_set, 'Train Dataset Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaaccca1063de97",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = vectorize_dataset(train_set, test_set, val_set)\n",
    "\n",
    "#set the evaluation set for early stop models\n",
    "eval_set = [(X_validation, y_validation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386587f854edd20d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Random Over-sampling\n",
    "RandomOverSampler will increase the data samples in the minority class (vishing). It makes the minority class have the same data samples as the majority class (non-vishing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41034b815c3483a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# define RandomOverSampler strategy\n",
    "sampling = RandomOverSampler(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f28640f3a0557c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75914154fdd41518",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SMOTE Over-sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91b1c78170ceda",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, KMeansSMOTE , ADASYN,SVMSMOTE,KMeansSMOTE,BorderlineSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df0cbc0c421fb5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define SMOTE strategy\n",
    "sampling = SMOTE(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340f0042868008f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Adaptive Synthetic (ADASYN) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafe0378c634756",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define ADASYN strategy\n",
    "sampling = ADASYN(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ca879f082db41",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### KMeansSMOTE method\n",
    "KMeans clustering before to over-sample using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85bdc23eef5fd8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define KMeansSMOTE strategy\n",
    "sampling = KMeansSMOTE(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621579831b997d42",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Borderline SMOTE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c1c3ac0d563fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define BorderlineSMOTE strategy\n",
    "sampling = BorderlineSMOTE(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a33c5001ed313",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SMOTE and cleaning using ENN method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58106fec70d7de42",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define SMOTEENN strategy\n",
    "sampling = SMOTEENN(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067e1517dea102d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SMOTETomek method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d4f31d5d04ca0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define SMOTETomek strategy\n",
    "sampling = SMOTETomek(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175df81bd88d2e69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SVMSMOTE method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a022303d7ee275",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define SVMSMOTE strategy\n",
    "sampling = SVMSMOTE(random_state=42) #sampling_strategy='minority', sampling_strategy parameter is to balance the class to have 1:1 data samples\n",
    "\n",
    "# Train the models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, sampling)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88d8ab99e0a7ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training models with Back-translation as text augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf393d7016fd6e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import the train_set, test_set, val_set\n",
    "train_set = pd.read_csv('train_set_clean.csv')\n",
    "test_set = pd.read_csv('test_set_clean.csv')\n",
    "val_set = pd.read_csv('val_set_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad31a181f527a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cda9389eac12a3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the class distribution of the train_set dataset\n",
    "plot_class_distribution(train_set, 'Train Dataset Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1cf2c81cf635a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import the augmented dataset from back-translation method\n",
    "train_set_en = pd.read_csv('train_set_en_clean.csv')\n",
    "train_set_ch = pd.read_csv('train_set_ch_clean.csv')\n",
    "train_set_ja = pd.read_csv('train_set_ja_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd682c856c89cdf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_set_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28664832c91679ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training with the English-Korean augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e58895e1be2b1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # concatenate train_set and train_set_en dataset and make a new dataset with only train_set['corpus'] and train_set['label'] columns. Add train_set_en['corpus_en'] and train_set_en['label'] columns to the new dataset.\n",
    "# train_set_en0 = train_set_en[['corpus_en', 'label']]\n",
    "# train_set_en0.columns = ['corpus', 'label']\n",
    "# train_set_en0\n",
    "\n",
    "# # concatenate the augmented train_set_en dataset with the original dataset to create the new train_set dataset for training the models with back-translation method as text augmentation method.  \n",
    "# train_set00 = pd.concat([train_set, train_set_en], ignore_index=True)\n",
    "# train_set00\n",
    "\n",
    "# Make new train_set dataset with only train_set['corpus'] and train_set['label'] columns.\n",
    "train_set_new = train_set[['corpus', 'label']]\n",
    "train_set_new.columns = ['corpus', 'label']\n",
    "train_set_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942e63eedcb52b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make new train_set_en dataset with only train_set_en['corpus_en'] and train_set_en['label'] columns. Rename the columns to 'corpus_en' to 'corpus'.\n",
    "train_set_en_new = train_set_en[['corpus_en', 'label']]\n",
    "train_set_en_new.columns = ['corpus', 'label']\n",
    "train_set_en_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078b8f44095eb7d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# concatenate the augmented train_set_en dataset with the original dataset to create the new train_set dataset for training the models with back-translation method as text augmentation method.\n",
    "train_set_EnKo = pd.concat([train_set_new, train_set_en_new], ignore_index=True)\n",
    "train_set_EnKo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3352ad2960cde5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the class distribution of the new train_set dataset \n",
    "plot_class_distribution(train_set_EnKo, 'En-Ko Augmented Train Set Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a421640b88f1421",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# vectorize the dataset\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = vectorize_dataset(train_set_EnKo, test_set, val_set)\n",
    "\n",
    "#set the evaluation set for early stop models\n",
    "eval_set = [(X_validation, y_validation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf53466604e08fa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training ML models with En-Ko augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9aeaa19edc93f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define the ML models\n",
    "models, es_models = define_models()\n",
    "\n",
    "# Define the Back-translation name En-Ko\n",
    "bt_name = 'BT-EnKo'\n",
    "\n",
    "# train the ML models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, bt_name=bt_name)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee006433397f84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training with the Chinese-Korean augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d3c9ba579167c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # concatenate train_set and train_set_ch dataset and make a new dataset with only train_set['corpus'] and train_set['label'] columns. Add train_set_ch['corpus_ch'] and train_set_ch['label'] columns to the new dataset.\n",
    "# train_set_ch0 = train_set_ch[['corpus_ch', 'label']]\n",
    "# train_set_ch0.columns = ['corpus', 'label']\n",
    "# train_set_ch0\n",
    "# \n",
    "# # concatenate the augmented train_set_ch dataset with the original dataset to create the new train_set dataset for training the models with back-translation method as text augmentation method.\n",
    "# train_set0 = pd.concat([train_set, train_set_ch0], ignore_index=True)\n",
    "# train_set0\n",
    "# \n",
    "# # Make new train_set dataset with only train_set['corpus'] and train_set['label'] columns.\n",
    "# train_set_new = train_set[['corpus', 'label']]\n",
    "# train_set_new.columns = ['corpus', 'label']\n",
    "# train_set_new\n",
    "\n",
    "# Make new train_set_ch dataset with only train_set_ch['corpus_ch'] and train_set_ch['label'] columns. Rename the columns to 'corpus_ch' to 'corpus'.\n",
    "train_set_ch_new = train_set_ch[['corpus_ch', 'label']]\n",
    "train_set_ch_new.columns = ['corpus', 'label']\n",
    "train_set_ch_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24f33b071b7f79",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# concatenate the augmented train_set_ch dataset with the original dataset to create the new train_set dataset for training the models with back-translation method as text augmentation method.\n",
    "train_set_ChKo = pd.concat([train_set_new, train_set_ch_new], ignore_index=True)\n",
    "train_set_ChKo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa7b6fa73ef638f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot the class distribution of the new train_set dataset\n",
    "plot_class_distribution(train_set_ChKo, 'Ch-Ko Augmented Train Set Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d30ff59909c4f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# vectorize the dataset\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = vectorize_dataset(train_set_ChKo, test_set, val_set)\n",
    "\n",
    "#set the evaluation set for early stop models\n",
    "eval_set = [(X_validation, y_validation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308601cb5c5083f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training ML models with Ch-Ko augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f86aa1fa77242",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define the ML models\n",
    "models, es_models = define_models()\n",
    "\n",
    "# Define the Back-translation name En-Ko\n",
    "bt_name = 'BT-ChKo'\n",
    "\n",
    "# train the ML models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, bt_name=bt_name)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42987f5dc77a0c21",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training with the Japanese-Korean augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a8b8b0fd3a68",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make new train_set_ja dataset with only train_set_ja['corpus_ja'] and train_set_ja['label'] columns. Rename the columns to 'corpus_ja' to 'corpus'.\n",
    "train_set_ja_new = train_set_ja[['corpus_ja', 'label']]\n",
    "train_set_ja_new.columns = ['corpus', 'label']\n",
    "train_set_ja_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2e7bbfb983a01",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# concatenate the augmented train_set_ja dataset with the original dataset to create the new train_set dataset for training the models with back-translation method as text augmentation method.\n",
    "train_set_JaKo = pd.concat([train_set_new, train_set_ja_new], ignore_index=True)\n",
    "train_set_JaKo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e43cb02bc0cc1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the class distribution of the new train_set dataset\n",
    "plot_class_distribution(train_set_JaKo, 'Ja-Ko Augmented Train Set Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db0e19f8269a5f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# vectorize the dataset\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = vectorize_dataset(train_set_JaKo, test_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5887d8669c2f9a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training ML models with Ja-Ko augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4aa600d1ed82b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define the ML models\n",
    "models, es_models = define_models()\n",
    "\n",
    "# Define the Back-translation name En-Ko\n",
    "bt_name = 'BT-JaKo'\n",
    "\n",
    "# train the ML models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, bt_name=bt_name)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ffa10d92267c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training models with combination of all back-translated datasets (EnKo, ChKo, JaKo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14042f835253ef6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# concatenate the augmented train_set_new, train_set_en_new, train_set_ch_new, train_set_ja_new dataset to a new dataset\n",
    "\n",
    "train_set_all = pd.concat([train_set_new, train_set_en_new, train_set_ch_new, train_set_ja_new], ignore_index=True)\n",
    "train_set_all\n",
    "\n",
    "# plot the class distribution of the new train_set dataset\n",
    "plot_class_distribution(train_set_all, 'All BT Augmented Train Set Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2285818539cff5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# vectorize the dataset\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = vectorize_dataset(train_set_all, test_set, val_set)\n",
    "\n",
    "#set the evaluation set for early stop models\n",
    "eval_set = [(X_validation, y_validation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde03459772f9ea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training ML model with Original+EnKo+ChKo+JaKo dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44db7e57f0718bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define the ML models\n",
    "models, es_models = define_models()\n",
    "\n",
    "# Define the Back-translation name\n",
    "bt_name = 'BT-All'\n",
    "\n",
    "# train the ML models\n",
    "df_results = train_models_sampling(models, es_models, X_train, y_train, eval_set, X_test, y_test, bt_name=bt_name)\n",
    "\n",
    "# Display the results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5561cf8500447d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bd5722ad4cb55",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "\n",
    "# use nested cross validation to evaluate the model with the best hyperparameters on the test set \n",
    "# define the model\n",
    "model = XGBClassifier(\n",
    "    early_stopping_rounds=10,\n",
    "    verbosity=2,\n",
    "    # n_estimators=2000,\n",
    "    # tree_method='hist',\n",
    "    # subsample=0.67,\n",
    "    # colsample_level=0.06,\n",
    "    # n_jobs=6,\n",
    "    # random_state=1234\n",
    ")\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# define the search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [100, 500, 1000]\n",
    "grid['max_depth'] = [10, 20, 30]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1]\n",
    "grid['subsample'] = [0.5, 0.7, 1.0]\n",
    "grid['colsample_bytree'] = [0.5, 0.7, 1.0]\n",
    "\n",
    "# define the search using nested cross-validation\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=3, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7853caaabc56f98",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X_train, y_train, scoring='accuracy', cv=cv_outer, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2a886092c140c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74f8c8f1ff41c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# summarize the best hyperparameter combination\n",
    "print('Best Hyperparameters: %s' % search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb583e782c5d071",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# report the best configuration\n",
    "print('Config: %s' % search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc55a91e282be88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# report all configurations\n",
    "means = search.cv_results_['mean_test_score']\n",
    "params = search.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b3b76246722e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#fit the model\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e9add334769ae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "yhat = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1889232c50a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980a5542ef58bb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b0141d5e93f43",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# use nested cross validation to evaluate the model with the best hyperparameters on the test set\n",
    "# define the model\n",
    "model = LGBMClassifier(\n",
    "    early_stopping_rounds=10,\n",
    "    verbosity=2,\n",
    "    # boost_from_average=False\n",
    "    # num_leaves=64,\n",
    "    # n_estimators=2000,\n",
    "    # feature_fraction=0.06,\n",
    "    # bagging_fraction=0.67,\n",
    "    # bagging_freq=1,\n",
    "    # n_jobs=6,\n",
    "    # random_state=1234\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eeea988694a335",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16669045b4c88f40",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696540f55b882709",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15bb877c1e1054",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb1f52f0258cc1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dcba2b835b3b9e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training model with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438822a507276724",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import the train_set, test_set, val_set\n",
    "train_set = pd.read_csv('train_set_clean.csv')\n",
    "test_set = pd.read_csv('test_set_clean.csv')\n",
    "val_set = pd.read_csv('val_set_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221500c32bba6417",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "# define the feature selection method\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_classif, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848890a22303f06e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87d10eb3707c76",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fd15af5037840",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deafcbd51a6b485",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = XGBClassifier(\n",
    "    # early_stopping_rounds=10,\n",
    "    verbosity=2,\n",
    "    # n_estimators=2000,\n",
    "    # tree_method='hist',\n",
    "    # subsample=0.67,\n",
    "    # colsample_level=0.06,\n",
    "    # n_jobs=6,\n",
    "    # random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c28a6c59675e28",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(X_train_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433280cd17c42fde",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f34abeec4935a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348497980a269f8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = LGBMClassifier(\n",
    "    # early_stopping_rounds=10,\n",
    "    verbosity=2,\n",
    "    # boost_from_average=False\n",
    "    # num_leaves=64,\n",
    "    # n_estimators=2000,\n",
    "    # feature_fraction=0.06,\n",
    "    # bagging_fraction=0.67,\n",
    "    # bagging_freq=1,\n",
    "    # n_jobs=6,\n",
    "    # random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73394d5516869b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(X_train_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403e0d8843dce95",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f191a3b3f1ce44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80733eccc8b8de7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
